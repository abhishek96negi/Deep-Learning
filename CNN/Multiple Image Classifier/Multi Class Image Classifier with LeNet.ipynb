{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutli CLass Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Result loss minimum and high accuarcy but predicting is not good. so that, we move on AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Select 6 feature convolution kernels with a size of 5 * 5 (without offset), and get 66 feature maps. The size of each feature map is 32−5 + 1 = 2832−5 + 1 = 28.\n",
    "# That is, the number of neurons has been reduced from 10241024 to 28 ∗ 28 = 784 28 ∗ 28 = 784.\n",
    "# Parameters between input layer and C1 layer: 6 ∗ (5 ∗ 5 + 1)\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 3)))\n",
    "# The input of this layer is the output of the first layer, which is a 28 * 28 * 6 node matrix.\n",
    "# The size of the filter used in this layer is 2 * 2, and the step length and width are both 2, so the output matrix size of this layer is 14 * 14 * 6.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# The input matrix size of this layer is 14 * 14 * 6, the filter size used is 5 * 5, and the depth is 16. This layer does not use all 0 padding, and the step size is 1.\n",
    "# The output matrix size of this layer is 10 * 10 * 16. This layer has 5 * 5 * 6 * 16 + 16 = 2416 parameters\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "# The input matrix size of this layer is 10 * 10 * 16. The size of the filter used in this layer is 2 * 2, and the length and width steps are both 2, so the output matrix size of this layer is 5 * 5 * 16.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# The input matrix size of this layer is 5 * 5 * 16. This layer is called a convolution layer in the LeNet-5 paper, but because the size of the filter is 5 * 5, #\n",
    "# So it is not different from the fully connected layer. If the nodes in the 5 * 5 * 16 matrix are pulled into a vector, then this layer is the same as the fully connected layer.\n",
    "# The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "# The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n",
    "model.add(Dense(84, activation='relu'))\n",
    "# The number of input nodes in this layer is 84 and the number of output nodes is 4. The total parameter is 84 * 4 + 4 = 340\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "# Compile\n",
    "model.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.ImageDataGenerator at 0x1f4c0199748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "train_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.ImageDataGenerator at 0x1f4c0199780>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1f4c0199c88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('E:/Parent1', target_size = (28,28),\n",
    "                                                 batch_size=128,\n",
    "                                                 class_mode='categorical')\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1f4c0351748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('E:/Parent1',\n",
    "                                            target_size = (28,28),\n",
    "                                            batch_size =128,\n",
    "                                            class_mode = 'categorical')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\abhishek negi\\.conda\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/2\n",
      "250/250 [==============================] - 1074s 4s/step - loss: 0.2124 - accuracy: 0.9413 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "250/250 [==============================] - 1020s 4s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6834e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f4c03519b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_set,epochs=2,steps_per_epoch = 250, verbose=1, validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "Test Loss: 0.00026834331220015883\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_set)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Multiple Class Image with LeNet.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAHlklEQVR4nCXV+49dVRXA8bXW3vucc993pjNzO50ObSltaYdSUR6dVpGQBsSIBEeMRWswKVHxBxMxgpKYaEiMMSjEH4RIYhMjwV9MFGOkSJxAVWzTDtAW6EwppdN5dzr3de557L3X8of+D998Pziz3AIAFFaIIl48AzKwAAAzM7OIeCeerUYMjGF24Nk5hyQKyQszkAMkokDp3Dsvor33BEIonlFECEAcMIsXFhGjKc0sM2tAETBKrIfYegA0qJVBRRoAchZDChERiRFwYa3tvFjPiAIsSKJZcubMiYgQiEEAAATJcquQAEVr0ERKKSLy3guiJnLMjoU9ACB24m7mmZlBSEQAAJC9984yIhoNSOJSZgZF7DwieSICAEQEgNQKiOTWMoIhrTTMHvuz9iIAoBAIWROKCLM4QtSgEFBg/Nb9Jkl2b+z/oCuvTR61HgGYAD0LohSM5FYKAf3pmSf23rrHoy6FGpfX2gCAwAqFQBCRiJjZsVjvJx58sLxwuWmtWHt9Y6A41P+LIy8LoWOPoOZOv/7Wibf3bW70nKsNDPR6KSoDnOOjXzpgHderNURExNS64eGRcqmw2uzYhZmNt4xHherRF383G6cV0UOD0ZcfeSROlsm5+cWF6el3Dx46PP/R+7ePH/AuieMeBqHWAT7/o8OlUqkdx1EU9npdrQMdGO+9Zpg69lZs8/G79vb19TXX4p//9qV7RtcFIR3PB9u2dOiO4N4vfq48MNxtrjaXr6ytXTl7cWHq+LEDn9qCv/7BwdmlztjY2OLs7MXLFxrrhq+urozv37t1866nn/zxfQ/d22ylfz+ZFGqVxcXFsXT61aUYyShlADjLe4j0zDf3mcq6ALNTU2fG999VLJXw0c/fcX2tWKpVe90ul+rNlblN/dWoWnzj3zNrq0vnwk98dP6/iKi1FgHLulJUzvlrRWd5QsoY6976y2+A2WapCQP2pEeG6h1Ra20/snlnvRrUhvrnZi/duX28/Y8TrRz3l6b3bKq8crm37cbd5Wpfp7kytGG0110NlTn+v/+IeOX8PVsHz069xhxMX/jw3OmzYzdt03vv/Up9/bDWAaK41pqp9wPAS889myZ5IOyHqt95+OHvlutPH3nT5/H2XbcD+GKhxoIUnLj7pq2j8VLbUmn99jxLdlQHhjddd+7MtF6ZPzc5ebS/XltaWtq0ebRYLIZa3bD7hnCw9ul9t7bnLx6dnHz25WM7btxSDIsLvZWVK1c2bNi4uNpyafazHz701PefaVTMyOYdR158vr3SefynT33mPkM8+8b16lI5Pn/w4NfKC2+svfP6bfvuqtPKLQOrQ+s3bb5p38Shb03+7aXp6dmp0++9/e4H8wtX337nvdkL55VSfQMjD379C8JsNH514gHB+OKZU+fPX9D1PRNhGKZpurI0V9o9MX7zze+dmSoNf3LD6IZLF2fQsQqjR5/8w8DghtXVWURUJCJMqJl5LdEjW3YqNblyNc5cMPGNb4dRsVoq6vXrGusaQ0kaB0GQJ7n1snP7Dm+dMWb3rrHlxaWoWChVaGX5ilYRixPWSB4AkOTQ4Z/88bkncutKhCMjIwRIRFpED61vXLows2Pn7qvtViHS2oRra6uz52ca64dbzebkP4/uGrt5Yf6cJgOICIoUMAsSgMj+XUO//+Wvqn3l42++3munxUgvrayWKmV8YGywXCwVCJI8K4RBFIRxL0NErXjv+J0nT560QievuPNzcyTACIaUE7628MfGtmSuFys0oWZrQaliodDp5TRQqVeCqN4YNia0jrLcW/YECik8deoUkM7jJM8y8I6IRCROE/DMzCTwwumPFlGZQHlnwzBklNMXPhZkUloAXImsBikXTGOob/t1I5ESmycgzndbHmS0SIjKsk+zrF+jE/bee5AbRwfjLEeitW6aAYZRZduGgVxEE+lyYNbasVeYs3M2S9MsLOhGbV1uJVUqEgwytOyVUvfcsFFF+tWzHxtjNFKJ7cZapRyaboDVQmgKka6E5XaLjIjzeafV1mSUsNi8Wq1mzjc7ibWJFUiSXi/rKUBrLbFtBBoRr4GYAgCLR1UtV/M8BZvHcTy30qFiZDLLiWNEqZTL7cwnDhSZTq9XW9dQoSFj5lLIvWNmEwa9PL9726i1NnPWkyJtkjRVRklYFKClThLVKjoRUlFQwGqzl8VZTwhD560xSut3LlxKkgQRT8zMAxoiEcKYpdvrXWOqHtKKdWmaGoWVCl7Ok7QTa60pJ2mnaZY7UwiDSIURpt4uXG2uNlt5HAsKKrpt0yCD906MszpQhUrZO2HmMAw92yAIGKibJMjYPzgQREW9uHyVlAJAdmyKBRZpDA5pVSiWKuzzcqU+u3i5L+KT860kzXtBiKmNTKA0kjJiCsVAKaUMYRgEzuUEXImqePizeyrVatxthyZK07RQKDj2nlQY6MgEndwFio69f3EphmZr+f7bxmrFSIG04t4rUx/muRORx+7f73PbarVKtbpShtDj4xMHQlQOUBDWNwYXFhbCMKQgzHtxsRiA86YYvvDXf4mufe+Ric7lj7MsC4zqpgkpA6HeuHXHuRPHCTGKNHnFLqUg/D9/X1eVyuCPCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x1F4ACD1E518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 3 - Making new predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(r'C:\\Users\\Abhishek Negi\\Desktop\\Pic\\IMG-20190620-WA0030.jpg', target_size = (28,28))\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[219., 234., 241.],\n",
       "        [219., 234., 241.],\n",
       "        [220., 233., 239.],\n",
       "        ...,\n",
       "        [217., 222., 225.],\n",
       "        [211., 219., 221.],\n",
       "        [208., 218., 220.]],\n",
       "\n",
       "       [[216., 231., 238.],\n",
       "        [218., 231., 237.],\n",
       "        [221., 232., 236.],\n",
       "        ...,\n",
       "        [221., 226., 229.],\n",
       "        [218., 223., 227.],\n",
       "        [216., 224., 227.]],\n",
       "\n",
       "       [[231., 239., 242.],\n",
       "        [227., 236., 241.],\n",
       "        [222., 233., 239.],\n",
       "        ...,\n",
       "        [223., 229., 229.],\n",
       "        [221., 226., 229.],\n",
       "        [221., 226., 230.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 80.,  48.,  27.],\n",
       "        [ 82.,  51.,  30.],\n",
       "        [ 82.,  51.,  31.],\n",
       "        ...,\n",
       "        [105.,  72.,  55.],\n",
       "        [107.,  72.,  53.],\n",
       "        [107.,  74.,  59.]],\n",
       "\n",
       "       [[100.,  63.,  47.],\n",
       "        [113.,  77.,  61.],\n",
       "        [102.,  65.,  47.],\n",
       "        ...,\n",
       "        [107.,  79.,  65.],\n",
       "        [110.,  82.,  70.],\n",
       "        [112.,  83.,  67.]],\n",
       "\n",
       "       [[115.,  83.,  68.],\n",
       "        [122.,  84.,  71.],\n",
       "        [118.,  84.,  72.],\n",
       "        ...,\n",
       "        [118.,  84.,  72.],\n",
       "        [116.,  80.,  64.],\n",
       "        [118.,  86.,  71.]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = image.img_to_array(test_image)\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[219., 234., 241.],\n",
       "         [219., 234., 241.],\n",
       "         [220., 233., 239.],\n",
       "         ...,\n",
       "         [217., 222., 225.],\n",
       "         [211., 219., 221.],\n",
       "         [208., 218., 220.]],\n",
       "\n",
       "        [[216., 231., 238.],\n",
       "         [218., 231., 237.],\n",
       "         [221., 232., 236.],\n",
       "         ...,\n",
       "         [221., 226., 229.],\n",
       "         [218., 223., 227.],\n",
       "         [216., 224., 227.]],\n",
       "\n",
       "        [[231., 239., 242.],\n",
       "         [227., 236., 241.],\n",
       "         [222., 233., 239.],\n",
       "         ...,\n",
       "         [223., 229., 229.],\n",
       "         [221., 226., 229.],\n",
       "         [221., 226., 230.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 80.,  48.,  27.],\n",
       "         [ 82.,  51.,  30.],\n",
       "         [ 82.,  51.,  31.],\n",
       "         ...,\n",
       "         [105.,  72.,  55.],\n",
       "         [107.,  72.,  53.],\n",
       "         [107.,  74.,  59.]],\n",
       "\n",
       "        [[100.,  63.,  47.],\n",
       "         [113.,  77.,  61.],\n",
       "         [102.,  65.,  47.],\n",
       "         ...,\n",
       "         [107.,  79.,  65.],\n",
       "         [110.,  82.,  70.],\n",
       "         [112.,  83.,  67.]],\n",
       "\n",
       "        [[115.,  83.,  68.],\n",
       "         [122.,  84.,  71.],\n",
       "         [118.,  84.,  72.],\n",
       "         ...,\n",
       "         [118.,  84.,  72.],\n",
       "         [116.,  80.,  64.],\n",
       "         [118.,  86.,  71.]]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('Multiple Class Image with LeNet.h5')\n",
    "result= model.predict(test_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abhishek Negi': 0, 'Chennu': 1, 'Dorami': 2, 'Rinki': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rinki\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'Abhishek Negi'\n",
    "    print(prediction)\n",
    "elif result[0][1]==1:\n",
    "    prediction = 'Cheenu'\n",
    "    print(prediction)\n",
    "elif result[0][2]==1:\n",
    "    prediction = 'Dorami'\n",
    "    print(prediction)\n",
    "elif result[0][3]==1:\n",
    "    prediction = 'Rinki'\n",
    "    print(prediction)\n",
    "else:\n",
    "    print('Not Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 6)         456       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 16)          2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 340       \n",
      "=================================================================\n",
      "Total params: 44,216\n",
      "Trainable params: 44,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
